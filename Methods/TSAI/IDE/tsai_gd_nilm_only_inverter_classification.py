# -*- coding: utf-8 -*-
"""TSAI_GD_NILM_Only_Inverter_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WqHjYxV419YILypYk6zlOQClu713C2wS

## Package installations and Google Drive Initialization
"""

from google.colab import drive
drive.mount('/content/drive')

#!pip uninstall -y tsai && pip install tsai
!pip uninstall -y tsai && pip install tsai==0.3.5

#!pip uninstall fastai
#!pip install --upgrade --force-reinstall --no-deps /content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/TSAI/fastai_modified/fastai/
!pip uninstall -y fastai && pip install fastai==2.7.10

#!pip install --upgrade --force-reinstall --no-deps /content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/TSAI/fastai_modified/fastai/

!pip install tensorflow==2.4.0
!pip install keras==2.4.0
!pip install kymatio
!pip install tqdm
!pip install iterative-stratification
!pip install scikit-multilearn

"""## Pre-Definitions"""

configs = {
            "N_GRIDS": 5,
            "SIGNAL_BASE_LENGTH": 12800,
            "N_CLASS": 5,
            "USE_NO_LOAD": False,
            "USE_HAND_AUGMENTATION": True,
            "MARGIN_RATIO": 0.15,
            "DATASET_PATH": "drive/MyDrive/Scattering_Novo/dataset_original/Synthetic_Full_iHall.hdf5",
            "TRAIN_SIZE": 0.9,
            "FOLDER_PATH": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/ST-NILM/SC4_Classify_Loads_and_Inverter/trained_models/",
            "FOLDER_DATA_PATH": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/ST-NILM/SC4_Classify_Loads_and_Inverter/trained_models/",
            "N_EPOCHS_TRAINING": 5000,
            "PERCENTUAL": [1],
            "INITIAL_EPOCH": 0,
            "TOTAL_MAX_EPOCHS": 5000,
            "SNRdb": None,  # Nível de ruído em db
            "LOSS": 'binary_crossentropy',  # 'bce_weighted_loss', 'focal_loss', "binary_crossentropy",
            "root_path": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/ST-NILM",
            "data_path": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/LSTM_TR/LSTM_TR_SRC/segments",
            "segments_path": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/LSTM_TR/LSTM_TR_SRC/segments",
            "source_models_folder": "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/ST-NILM/SC4_Classify_Loads_and_Inverter/trained_models/",
            'tsai_path': "/content/drive/MyDrive/Doutorado/Artigo_Dataset/Colab/TSAI",
            "stnilm_path": "/content/drive/MyDrive/Scattering_Novo/src"
        }

import sys
sys.path.append("ST-NILM/src")
sys.path.append("./TSAI")

from LoadSegments import LoadSegments

loadSegments = LoadSegments(configs)

subsets_selector = 0
normalized = 0
scenario = 4
choose_model = 1
experiment = 3 # binary_only_inverter


dict_subset = {0: 'Aggregated', 1: 'Individual', 2: 'All'}
dict_normalized = {0: '', 1: 'Normalized'}
dict_scenario = {1: 'SC1', 2: 'SC2', 3: 'SC3', 4: 'SC4', 5: 'SC5', 6: 'SC6'}
dict_models = {1: 'InceptionTime', 2: 'Sequencer', 3: 'TST', 4: 'TSiT'}
dict_experiment = {1: 'multiclass_loads_and_inverter', 2: 'multiclass_only_loads', 3: 'binary_only_inverter' }

output_model_path = configs["tsai_path"] + '/models/'
output_model_path = output_model_path + dict_models[choose_model] + '/'

from tsai.all import *
my_setup()

if dict_experiment[experiment]!= 'binary_only_inverter':
  PATH = Path(output_model_path + dict_scenario[scenario] + '_' + dict_subset[subsets_selector] + dict_normalized[normalized] + '/Multilabel.pkl')
else:
  PATH = Path(output_model_path + dict_scenario[scenario] + '_' + dict_subset[subsets_selector] + dict_normalized[normalized] + '/Binary_only_inverter.pkl')

PATH.parent.mkdir(parents=True, exist_ok=True)

print(PATH)

train_x, train_y, test_x, test_y = loadSegments.load_segments(subsets_selector=subsets_selector, normalized=normalized)
print(train_x.shape)
print(test_x.shape)

def bin_to_multi(y_bin):
    y_multi = [] # empty list
    y = []
    loads_dict = {0: 'Iron', 1: 'Motor', 2: 'Driller', 3: 'Dimmer', 4: 'Inverter' }
    for k in range(y_bin.shape[0]):
        for load in range(y_bin.shape[1]):
            if y_bin[k,load]==1:
                if len(y)==0:
                    y = [loads_dict[load]]
                else:
                    y.append(loads_dict[load])
        y_multi.append(y)
        y = []
    return y_multi

def bin_to_category(y_bin):
    y_category = [] # empty list
    y = []
    loads_dict = {0: 'Iron', 1: 'Motor', 2: 'Driller', 3: 'Dimmer', 4: 'Inverter' }
    for k in range(y_bin.shape[0]):
        for load in range(y_bin.shape[1]):
            if y_bin[k,load]==1:
                if len(y)==0:
                    y = [load]
                else:
                    y.append(load)
        y_category.append(y)
        y = []
    return y_category


def construct_dataset_structure(X, y_multi, tfms, batch_tfms, train_index=None, val_index=None): # train_index and val_index are the same list of index we used before
    train_index = train_index.astype(int)
    val_index = val_index.astype(int)
    if train_index.any()==None:
        # There is no validation subset
        splits=None
    elif train_index.shape[0] != 0:
        splits = [train_index, val_index]
    dls = get_ts_dls(X, y_multi, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=16)


    #dls = get_ts_dls(X, y_multi, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])
    return dls

import numpy as np

#all_x = np.append(train_x,test_x, axis=0)
#all_y = np.append(train_y,test_y, axis=0)
#del train_x, train_y, test_x, test_y

# subsets_selector
# 0 - Aggregated
# 1 - Individual
# 2 - All



#labeler = ReLabeler(class_map)
#y_multi = labeler(y)
y_multi = bin_to_multi(train_y[:,0,:])
y_category = bin_to_category(train_y[:,0,:])
y_bin = train_y[:,0,:] # For training and validation

# Training (and validation) Features
X = train_x
X = np.moveaxis(X, 1, 2)
X = X[:,0,:] # isso foi um teste.. podemos comentar caso não dê certo


if dict_experiment[experiment]=='binary_only_inverter':
  y_bin = y_bin[:,-1] # last column is the inverter label
  y_bin_test = test_y[:,0,-1] # last column is the inverter label
  print('Number of training samples with inverter: ', np.sum(y_bin==1))
  print('Number of training samples without inverter: ', np.sum(y_bin==0))
  print('Number of testing samples with inverter: ', np.sum(y_bin_test==1))
  print('Number of testing samples without inverter: ', np.sum(y_bin_test==0))

#label_counts = collections.Counter([a for r in y_multi for a in r])
#print('Counts by label:', dict(label_counts))

#del all_x, all_y

from tsai.basics import *



def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True, by_sample=False):
    "Computes accuracy when `inp` and `targ` are the same size."
    if sigmoid: inp = inp.sigmoid()
    correct = (inp>thresh)==targ.bool()
    if by_sample:
        return (correct.float().mean(-1) == 1).float().mean()
    else:
        inp,targ = flatten_check(inp,targ)
        return correct.float().mean()



label_counts = collections.Counter([a for r in y_multi for a in r])




def precision_multi(inp, targ, thresh=0.5, sigmoid=True):


    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh

    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    precision = TP/(TP+FP)
    return precision

def recall_multi(inp, targ, thresh=0.5, sigmoid=True):


    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh

    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()

    recall = TP/(TP+FN)
    return recall

def specificity_multi(inp, targ, thresh=0.5, sigmoid=True):


    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh

    correct = pred==targ.bool()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    specificity = TN/(TN+FP)
    return specificity

def balanced_accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):


    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh

    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    TPR = TP/(TP+FN)
    TNR = TN/(TN+FP)
    balanced_accuracy = (TPR+TNR)/2
    return balanced_accuracy

def Fbeta_multi(inp, targ, beta=1.0, thresh=0.5, sigmoid=True):


    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh

    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    precision = TP/(TP+FP)
    recall = TP/(TP+FN)
    beta2 = beta*beta

    if precision+recall > 0:
        Fbeta = (1+beta2)*precision*recall/(beta2*precision+recall)
    else:
        Fbeta = 0
    return Fbeta

def F1_multi(*args, **kwargs):
    return Fbeta_multi(*args, **kwargs)  # beta defaults to 1.0

metrics =[accuracy_multi, precision_multi, recall_multi, F1_multi]




if dict_experiment[experiment]!= 'binary_only_inverter':
  tfms = [None, TSMultiLabelClassification()]  # TSMultiLabelClassification() == [MultiCategorize(), OneHotEncode()]
  batch_tfms = TSStandardize()
  # Generate train and validation index
  index = np.linspace(start=0, stop=len(y_multi)-1, num=len(y_multi)) # 0, 1, 2, 3, ... , y_multi.shape[0]
  train_index = np.random.choice(index, round(0.9*index.shape[0]), replace=False)
  val_index = np.random.choice(index, round(0.1*index.shape[0]), replace=False) # in fact, this is the test subset
  dls = construct_dataset_structure(X, y_bin, tfms=tfms, batch_tfms=batch_tfms, train_index=train_index, val_index=val_index)
  dls.dataset
  dls.show_batch(sharey=True)
  if dict_models[choose_model]=='InceptionTime':
      learn = ts_learner(dls, InceptionTimePlus, metrics=metrics)
  elif dict_models[choose_model]=='Sequencer':
      learn = ts_learner(dls, TSSequencerPlus, metrics=metrics)
  elif dict_models[choose_model]=='TST':
      learn = ts_learner(dls, TSTPlus, metrics=metrics)
  elif dict_models[choose_model]=='TSiT':
      learn = ts_learner(dls, TSiTPlus, metrics=metrics)
  else:
      print("Model does not exist.")
  learn.fit_one_cycle(10, 1e-3) # Fit model multi label


else:
  tfms = [None, TSClassification()] # binary classification
  batch_tfms = TSStandardize()
  # Generate train and validation index
  index = np.linspace(start=0, stop=len(y_multi)-1, num=len(y_multi)) # 0, 1, 2, 3, ... , y_multi.shape[0]
  train_index = np.random.choice(index, round(0.9*index.shape[0]), replace=False)
  val_index = np.random.choice(index, round(0.1*index.shape[0]), replace=False) # in fact, this is the test subset
  train_index = train_index.astype(int)
  val_index = val_index.astype(int)
  splits = [train_index, val_index]
  if dict_models[choose_model]=='InceptionTime':
    clf = TSClassifier(X, y_bin, splits=splits, arch="InceptionTimePlus", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())
    clf.fit_one_cycle(10, 3e-4)
    #clf.export("clf.pkl")
  elif dict_models[choose_model]=='Sequencer':
    clf = TSClassifier(X, y_bin, splits=splits, arch="TSSequencerPlus", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())
    clf.fit_one_cycle(10, 3e-4) # fit binary model
    #clf.export("clf.pkl")
